{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM2hl2tm4QVfBXr1rkHg9JS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GiorgosMaragkopoulos/Quantum-data-encoding-using-QAE-PQAE/blob/main/QAE_Iris.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Quantum Autoencoders (QAEs) for latent space encoding of the Iris dataset vs linear autoencoders"
      ],
      "metadata": {
        "id": "uBigHUbBlygF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this jupyter notebook, I present the implementation of a Quantum autoencoder (QAE), which is essentially an autoencoder with a quantum feature map in the bottleneck. There will be a comparison between the performance of the model in terms of the reconstruction error with the QAE encoding VS without it (same structure, without the quantum feature map). The dataset in this example is going to be the Iris dataset, $l^2$-normalized per row."
      ],
      "metadata": {
        "id": "MFqwNiYFmB39"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqoESpSUcbde",
        "outputId": "3656d264-a881-419f-a5dc-e8b1e9fda5bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [100/2000], Loss: 0.0563\n",
            "Epoch [200/2000], Loss: 0.0239\n",
            "Epoch [300/2000], Loss: 0.0214\n",
            "Epoch [400/2000], Loss: 0.0208\n",
            "Epoch [500/2000], Loss: 0.0204\n",
            "Epoch [600/2000], Loss: 0.0195\n",
            "Epoch [700/2000], Loss: 0.0153\n",
            "Epoch [800/2000], Loss: 0.0070\n",
            "Epoch [900/2000], Loss: 0.0036\n",
            "Epoch [1000/2000], Loss: 0.0033\n",
            "Epoch [1100/2000], Loss: 0.0032\n",
            "Epoch [1200/2000], Loss: 0.0032\n",
            "Epoch [1300/2000], Loss: 0.0031\n",
            "Epoch [1400/2000], Loss: 0.0031\n",
            "Epoch [1500/2000], Loss: 0.0032\n",
            "Epoch [1600/2000], Loss: 0.0031\n",
            "Epoch [1700/2000], Loss: 0.0031\n",
            "Epoch [1800/2000], Loss: 0.0031\n",
            "Epoch [1900/2000], Loss: 0.0031\n",
            "Epoch [2000/2000], Loss: 0.0031\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler ,MinMaxScaler , Normalizer\n",
        "from torch.nn.functional import normalize\n",
        "\n",
        "\n",
        "def set_seed(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU.\n",
        "    torch.backends.cudnn.deterministic = True  # may slow down training.\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "# Example usage\n",
        "set_seed(3)\n",
        "\n",
        "\n",
        "# Load Iris dataset\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Convert to PyTorch tensor before normalization\n",
        "normalizer = Normalizer(norm='l2')\n",
        "X = normalizer.fit_transform(X)\n",
        "\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "X = torch.tensor(X, dtype=torch.float32)\n",
        "\n",
        "# Define the autoencoder model\n",
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Autoencoder, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(4, 3)  # 4 inputs to 3 nodes (bottleneck)\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(3, 4),\n",
        "            nn.Linear(4,4)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.decoder(x)\n",
        "        return x\n",
        "\n",
        "# Instantiate the model, define loss function and optimizer\n",
        "model = Autoencoder()\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.RMSprop(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training the autoencoder\n",
        "num_epochs = 2000\n",
        "for epoch in range(num_epochs):\n",
        "    # Forward pass\n",
        "    outputs = model(X)\n",
        "    loss = criterion(outputs, X)\n",
        "\n",
        "    # Backward pass and optimization\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Print progress\n",
        "    if (epoch+1) % 100 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Quantum Autoencoder starts with an input layer of 4 neurons and passes to the bottleneck which is a hidden layer of 3 neurons. These 3 neurons are used as coefficients to the generator, and 2 complex numbers form 4 real numbers (2 real numbers and 2 imaginary numbers), which are then decoded to the original 4 dimensional output."
      ],
      "metadata": {
        "id": "O6Vv9Id4YZm6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Quantum_Autoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Quantum_Autoencoder, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(4, 3)  # 4 inputs to 3 nodes (bottleneck)\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(4, 4)  # 3 nodes to 4 outputs\n",
        "        )\n",
        "\n",
        "\n",
        "        self.q0 = torch.tensor([[1], [0]], dtype=torch.cfloat)\n",
        "\n",
        "        # Define the Pauli matrices\n",
        "        self.sigma2 = torch.tensor([[0, 1], [1, 0]], dtype=torch.complex64)\n",
        "        self.sigma3 = torch.tensor([[0, -1j], [1j, 0]], dtype=torch.complex64)\n",
        "        self.sigma4 = torch.tensor([[1, 0], [0, -1]], dtype=torch.complex64)\n",
        "\n",
        "\n",
        "\n",
        "        # Collect the Gell-Mann matrices in a list\n",
        "        self.generators = [ self.sigma2, self.sigma3, self.sigma4 ]\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "\n",
        "        logits = torch.empty(150, 4, dtype=torch.float)\n",
        "\n",
        "        for i in range(150):\n",
        "            encoded = torch.zeros([2,2], dtype=torch.cfloat)\n",
        "            for index in range(3):\n",
        "                encoded += (1j  *  x[i][index]*  self.generators[index%3])\n",
        "\n",
        "\n",
        "            Exp_matrix = torch.matrix_exp(encoded )\n",
        "            qubit_1 = self.q0\n",
        "\n",
        "\n",
        "            qubit_1 = torch.matmul(Exp_matrix, qubit_1).T\n",
        "\n",
        "            real_part_1 = qubit_1.real.squeeze()  # Extract the real part and remove any unnecessary dimensions\n",
        "            imaginary_part_1 = qubit_1.imag.squeeze()  # Extract the imaginary part and remove any unnecessary dimensions\n",
        "\n",
        "            # Concatenate qutrit_6_elements with squared_elements\n",
        "            qubit_4_elements = torch.cat((real_part_1, imaginary_part_1  ) , dim=0)\n",
        "\n",
        "\n",
        "            logits[i] =  qubit_4_elements\n",
        "\n",
        "\n",
        "        x = self.decoder(logits)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Instantiate the model, define loss function and optimizer\n",
        "qae = Quantum_Autoencoder()\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.RMSprop(qae.parameters(), lr=0.001)\n",
        "\n",
        "# Training the autoencoder\n",
        "num_epochs = 2000\n",
        "for epoch in range(num_epochs):\n",
        "    # Forward pass\n",
        "    outputs = qae(X)\n",
        "    loss = criterion(outputs, X)\n",
        "\n",
        "    # Backward pass and optimization\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Print progress\n",
        "    if (epoch+1) % 100 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJ1sEDzVdk_P",
        "outputId": "50a9fc7b-22d4-4dc3-8d26-2f9b96999786"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [100/2000], Loss: 0.1420\n",
            "Epoch [200/2000], Loss: 0.0833\n",
            "Epoch [300/2000], Loss: 0.0566\n",
            "Epoch [400/2000], Loss: 0.0345\n",
            "Epoch [500/2000], Loss: 0.0171\n",
            "Epoch [600/2000], Loss: 0.0086\n",
            "Epoch [700/2000], Loss: 0.0052\n",
            "Epoch [800/2000], Loss: 0.0038\n",
            "Epoch [900/2000], Loss: 0.0030\n",
            "Epoch [1000/2000], Loss: 0.0024\n",
            "Epoch [1100/2000], Loss: 0.0019\n",
            "Epoch [1200/2000], Loss: 0.0015\n",
            "Epoch [1300/2000], Loss: 0.0014\n",
            "Epoch [1400/2000], Loss: 0.0013\n",
            "Epoch [1500/2000], Loss: 0.0012\n",
            "Epoch [1600/2000], Loss: 0.0012\n",
            "Epoch [1700/2000], Loss: 0.0012\n",
            "Epoch [1800/2000], Loss: 0.0012\n",
            "Epoch [1900/2000], Loss: 0.0012\n",
            "Epoch [2000/2000], Loss: 0.0012\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The reconstruction loss is 3 times lower in the quantum autoencoder, in contrast to the purely classical version."
      ],
      "metadata": {
        "id": "ZIxACQ1_dkKT"
      }
    }
  ]
}